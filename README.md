# E資格対策

## 1 応用数学

### (1) 確率・統計

- 一般的な確率分布
    - ベルヌーイ分布
    - 多項分布
    - ガウス分布
- ベイズ則

### (2) 情報理論
- 情報理論
    - 情報量

## 2 機械学習

### (1) 機械学習の基礎
- 学習アルゴリズム
    - 教師あり学習
    - 教師なし学習
    - 半教師あり学習
    - 転移学習

## (1) 機械学習の基礎

- 機械学習とは
機械学習とは、与えられた問題や課題または環境に応じてコンピュータ自身が学習し、学習結果を生かした問題解決や課題解決などを行う仕組み全体のことをいう
その内、機械学習はコンピューターに大量のデータを学習させ、データに潜むパターンやルールを発見させる技術

- 機械学習を導入すると・・・
    - 人間では処理しきれない大量のデータを分析することを可能
    - 業務の効率化やコスト削減などの効果が期待


# 学習アルゴリズム
- アルゴリズムとは特定の問題を解く手順を、単純な計算や操作の組み合わせとして明確に定義したもの

# 教師あり学習

- 教師あり学習とは、問題の答えをコンピュータに与えることで機械学習のモデルを学習させていく手法
「特徴を表すデータ」と「答えである目的データ」があることが前提
    - 分類問題
      ロジスティック回帰など
    - 回帰問題
      線形回帰など

教師あり学習アルゴリズムと分類及び回帰の適用範囲
| 番号 | アルゴリズム名 | 分類 | 回帰 |
| ------------- | ------------- | ------------- | ------------- |
| 01 | 線形回帰 | × ｜ ◯ |
| 02 | 正則化 | × ｜ ◯ |
| 03 | ロジスティック回帰 | ◯ ｜ × |
| 04 | サポートベクトルマシン | ◯ ｜ ◯ |
| 05 | サポートベクトルマシン(カーネル法) | ◯ ｜ ◯ |
| 06 | ナイーブベイズ | ◯ ｜ × |
| 07 | ランダムフォレスト | ◯ ｜ ◯ |
| 08 | ニューラルネットワーク | ◯ ｜ ◯ |
| 09 |  K近傍法（KNN） | ◯ ｜ ◯ |

- 線形回帰


# 教師なし学習

教師なし学習では特徴を表すデータを入力とし、そのデータを変換して別の形式で表現したり、データの部分集合を見つけたりすることで、入力データの構造を理解することが主な目的

- PCA
- LSA
- NMF
- LDA
- k-means法
- 混合ガウスモデル
- LLE
- t-SNE

# 半教師あり学習

半教師あり学習（Semi-Supervised Learning）とは、教師あり学習と教師なし学習を組み合わせて学習する方法のことである

[qiita_半教師学習](https://qiita.com/dcm_ishikawa/items/584cd373f49dd917566a)

# 転移学習

転移学習とは、機械学習手法の一つで、あるタスクに対して訓練されたモデルをそれと関連したタスクに応用する手法
転移学習は、モデルを一から訓練する必要を無くし、開発者の時間的なロスを最小化することを目標
転移学習の関連手法には、ファインチューニングや蒸留がある

- ファインチューニング
新たに学習するデータセットが多いケースでは、転移学習をそのまま行うとかえって時間がかかってしまう場合があります。
このような事態に対処するには「一度解いた設問の解法を、別の設問のために微調整」することが必要です。これがファインチューニングです。
ファインチューニングでは既存の学習済みモデルの一部と、新たに追加したモデルを合わせた全体の微調整を行います。こうしてモデル全体のデータを再学習することで、汎化性能をより向上させます。

- 蒸留
蒸留は、既に学習してあるモデルを使用し、より軽量なモデルを生み出すことです。学習済みの教師モデルの出力を生徒モデルの学習に利用します。
教師モデルから生徒モデル間の損失は「ソフトターゲットロス」と呼ばれます。また、生徒モデルの学習データの正解ラベルを「ハードターゲット」、クロスエントロピーなどの損失は「ハードターゲットロス」とそれぞれ呼ばれます。
ラベル付きデータを利用する場合はこれら2種類のターゲットロスを用い、ラベルなしのデータを利用する場合はソフトターゲットロスのみを用いて学習を行います。 蒸留は既存の高度で大きなネットワークをシンプルなネットワークに軽量化する目的で用いられます。

## 最尤推定
- 機械学習課題
    - 能力、過剰適合、過小適合
    - 次元の呪い
- ハイパーパラメータ
- 検証集合
    - 学習データ、検証データ、テストデータ
    - ホールドアウト法
    - k-分割交差検証法
- 最尤推定
    - 条件付き対数尤度と平均二乗和誤差

### (2) 実用的な方法論
- 性能指標
- ハイパーパラメータの選択
    - 手動でのハイパーパラメータ調整
    - グリッドサーチ
    - ランダムサーチ
    - モデルに基づくハイパーパラメータの最適化

### (3) 強化学習
- 方策勾配法
- 価値反復法

## 3 深層学習

### (1) 順伝搬型ネットワーク

- 全結合型ニューラルネットワーク
- 損失関数
    - 最尤推定による条件付き分布の学習
- 活性化関数
    - シグモイド関数
    - softmax関数
    - ReLU、Leaky ReLU
    - tanh
- 誤差逆伝播法及びその他の微分アルゴリズム
    - 計算グラフ
    - 微積分の連鎖率
    - 誤差逆伝播のための連鎖率の再起的な適用
    - シンボル間の微分
    - 一般的な誤差逆伝播法

### (2) 深層モデルのための正則化

- パラメータノルムペナルティー
    - L2パラメータ正則化
    - L1正則化
- データ集合の拡張
    - Random Flip・Erase・Crop・Contrast・Brightness・Rotate、MixUp
- ノイズに対する頑健性
    - 出力目標へのノイズ注入
- マルチタスク学習
- 早期終了
- スパース表現
- バギングやその他のアンサンブル手法
- ドロップアウト

### (3) 深層モデルのための最適化

- 学習と純粋な最適化の差異
    - バッチアルゴリズムとミニバッチアルゴリズム
- 基本的なアルゴリズム
    - 確率的勾配降下法
    - モメンタム
- パラメータの初期化戦略
- 適応的な学習率をもつアルゴリズム
    - AdaGrad
    - RMSProp
    - Adam
- 最適化戦略とメタアルゴリズム
    - バッチ正規化
    - Layer正規化
    - Instance正規化
    - 教師あり事前学習

### (4) 畳み込みネットワーク

- 畳込み処理
- プーリング

### (5) 回帰結合型ニューラルネットワークと再帰的ネットワーク

- 回帰結合型のニューラルネットワーク
- 双方向RNN
- Encoder-decoderと　Sequence-to-Sequence
- 長期依存性の課題
- ゲート付きRNN
    - LSTM
    -  GRU
- 長期依存性の最適化
    - 勾配クリッピング
- Attention

### (6) 生成モデル

- 識別モデルと生成モデル
- オートエンコーダ
    - VAE
    - VQ-VAE
- GAN
    - DCGAN
    - Conditional GAN

### (7) 深層強化学習

- 深層強化学習のモデル
    - AlphaGo
    - A3C

### (8) グラフニューラルネットワーク

- グラフ畳み込み

### (9) 深層学習の適応方法

- 画像認識
    - GoogLeNet
    - Resnet、WideResNet
    - DenseNet
    - EfficientNet
- 画像の局在化・検知・セグメンテーション
    - FasterR-CNN
    - YOLO
    - SSD
    - MaskR-CNN
    - FCOS
- 自然言語処理
    - WordEmbedding
    - Transformer
    - BERT
    - GPT-n
- 音声処理
    - WaveNet
    - 高速フーリエ変換
    - メル尺度
    - CTC
- スタイル変換
    - pix2pix

### (10) 距離学習(Metric Learning)

- 2サンプルによる比較
    - Siamesenet
- 3サンプルによる比較
    - TripletLoss

### (11) メタ学習(Meta Learning)

- 初期値の獲得
    - MAML

### (12) 深層学習の説明性

- 判断根拠の可視化
    - Grad-CAM
- モデルの近似
    - LIME
    - SHAP

## 4 開発・運用環境

### (1) ミドルウェア

- 深層学習ライブラリ

### (2) エッジコンピューティング

- 軽量なモデル
    - MobileNet
- モデルの軽量化
    - プルーニング
    - 蒸留
    - 量子化

### (3) 分散処理

- モデル並列化
- データ並列化

### (4) アクセラレータ

- デバイスによる高速化
    - GPU

### (5) 環境構築

- コンテナ型仮想化
    - Docker
