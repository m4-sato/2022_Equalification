{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q20MtcfXAtt6"
   },
   "source": [
    "# 10. 画像処理分野\n",
    "\n",
    "## 概要\n",
    "\n",
    "本演習では ResNet の Residual Block を穴埋め形式で実装します。\n",
    "\n",
    "なお、予め用意されたコードはそのまま使用し、指示された穴埋め部を編集してください。  \n",
    "演習問題文は<font color=\"Red\">赤字</font>です。\n",
    "\n",
    "また、乱数設定により実行結果が異なるため、<font color=\"Red\">コードを完成させたあと、必ずもう一度一番上のセルから順に最後まで実行して結果を確認してください。</font>\n",
    "\n",
    "所要時間：<font color=\"Red\">5~8時間</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2fJuwinlOPU"
   },
   "source": [
    "### 【Google colabのみ実行】ライブラリのインストール\n",
    "\n",
    "必要なライブラリのインストールと、実行環境のバージョンを統一します。<br>\n",
    "\n",
    "使用するライブラリ名とバージョンは配布資料の<font color=Red>「requirements.txt」</font>で確認できます。\n",
    "\n",
    "※以下のセルを実行しましたら、「ランタイム」→「ランタイムを再起動」により<font color=Red>再起動</font>を行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eW7MZHB0nm6Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Google Colab\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Google colab環境であるか判定\n",
    "if 'google.colab' in sys.modules:\n",
    "    # ライブラリのインストール\n",
    "    !pip install tensorflow==2.8.0\n",
    "else:\n",
    "    print(\"Not Google Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7QQUqwOppyG"
   },
   "source": [
    "### ライブラリのインポート\n",
    "\n",
    "必要なライブラリのインストールを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Zyio3NcM7OK-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.utils import data_utils\n",
    "\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except:\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    \n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# GPU が利用できる場合は、GPU上で学習を行います。\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ul1XyFF_KqlM"
   },
   "source": [
    "### データセットの準備\n",
    "\n",
    "データセットには、cifar10 を使用します。\n",
    "\n",
    "cifar10 は10種類のクラスを含まれており、  \n",
    "学習データ 50000枚、テストデータ 10000枚で構成されています。\n",
    "\n",
    "データは 3チャンネル(RGB)の縦横 32×32 の配列`(3, 32, 32)`となっています。\n",
    "\n",
    "本演習では実行時間の関係上、飛行機と自動車の画像500枚ずつに限定して学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "uUdLnG9vKqlN"
   },
   "outputs": [],
   "source": [
    "# 画像データを標準化する際の平均と分散、およびバッチサイズ\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "batch_size = 8\n",
    "\n",
    "num_data = 500\n",
    "num_classes = 2\n",
    "\n",
    "# テストデータのダウンロード\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "# 学習データから飛行機と自動車の画像を抽出\n",
    "mini_data = [[] for x in range(num_classes)]\n",
    "idx_list = list(range(2))\n",
    "for img, tgt in zip(x_train, y_train):\n",
    "    if tgt in idx_list and len(mini_data[int(tgt)]) < num_data:\n",
    "        mini_data[int(tgt)].append(img)\n",
    "mini_data = np.array(mini_data, dtype=x_train.dtype).reshape(-1, 32, 32, 3)\n",
    "\n",
    "# 学習データ用の正解ラベルを作成\n",
    "mini_targets = []\n",
    "for i in idx_list:\n",
    "    tgt = [i] * num_data\n",
    "    mini_targets += tgt\n",
    "\n",
    "# 学習データに適用する前処理\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.Resizing(224, 224),                      # 短い辺の長さがresizeの大きさになる\n",
    "  layers.RandomFlip(mode='horizontal', seed=1),   # ランダムに左右に反転する\n",
    "  layers.Rescaling(1./255),                       #[0, 255]の範囲にある入力データを[0, 1]の範囲に再スケールする\n",
    "  layers.Normalization(mean=mean, variance=std)   # 色情報の標準化\n",
    "])\n",
    "mini_data = data_augmentation(mini_data)\n",
    "\n",
    "# テストデータのデータローダ\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((mini_data,mini_targets)).shuffle(10000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mPjrn1UGPV0"
   },
   "source": [
    "## 1. ResNetを用いたCIFAR10の分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHFBTqXfAtt7"
   },
   "source": [
    "### ResNetについて\n",
    "\n",
    "CNNでは多層化することでネットワークの表現能力が向上することが知られているが、同時に入力層付近で勾配消失が起こりうまく学習できなくなってしまうという問題や勾配消失以外にも単純に層を深くすると反って精度が悪くなってしまうという劣化問題もあります。\n",
    "\n",
    "ResNetのResidual Blockは勾配消失や劣化問題に対して、skip connectionを導入することで勾配が出力層から入力層まで消失することなく伝播できるようになり、ネットワークをより多層化することができました。\n",
    "\n",
    "### bottleneckのアーキテクチャ\n",
    "\n",
    "3層の畳み込み層とskip connectionから構成されます。\n",
    "図の例では、256次元の特徴マップが入力された場合の構造を示しています。\n",
    "\n",
    "この構造のポイントは、\n",
    "- 1層目と二層目の畳み込み層で次元数を減少させることで、必要なパラメータ数を削減している。\n",
    "- 3層目の次元数を復元することで、最終的に得られる特徴マップのサイズはPlainアーキテクチャと同じになる。\n",
    "\n",
    "このような構造により、同じパラメータ数で多層化することができるという利点があります。\n",
    "\n",
    "<img src=\"data:image/jpeg;base64,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\" />\n",
    "\n",
    "また、重要な特徴表現を獲得するためには、次元数を増加させる必要があります。そのため、ResNetでは一部のレイヤーでダウンサンプリングしてから次元数を増やす処理を行っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_expoTmlK_g"
   },
   "source": [
    "### ResNet の実装\n",
    "\n",
    "ライブラリでは、VGG や ResNet など有名なネットワークはすでに実装されていて、手軽に利用できます。  \n",
    "本演習では理解のために ResNet の Residual Block のみを自ら実装してみましょう。  \n",
    "また、今回扱う Residual Block は Bottleneck アーキテクチャになります。\n",
    "\n",
    "* <font color=\"Red\">問1. ResNet の Bottleneckレイヤー を完成させてください。</font>\n",
    "  * <font color=\"Red\">問1-1. ダウンサンプリングを行う処理を記述してください。<br>\n",
    "    なお、コード入力の際は下記コードの```[a]```および```[b]```の部分に適切な変数または数値を入力してから転記してください。</font><br>\n",
    "      * 問1-1-1 ```layers.Conv2D([a-1], [b-1], strides=stride, name=name + '_1_conv')(x)```<br>\n",
    "      * 問1-1-2 ```layers.Conv2D([a-2], [b-2], padding='SAME', name=name + '_2_conv')(x)```<br>\n",
    "      * 問1-1-3 ```layers.Conv2D([a-3], [b-3], name=name + '_3_conv')(x)```<br>\n",
    "  * <font color=\"Red\">問1-2. skip connectionを行う処理を記述してください。</font>\n",
    "\n",
    "【ヒント】\n",
    "skip connectionは畳み込み層の出力`x`と層をまたいだ`shortcut`を足し合わせる処理です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Convolution(x, filters, stride=1):\n",
    "#     x = layers.Conv2D(filters, 5, strides=stride)(x)\n",
    "#     x = layers.Activation('relu')(x)\n",
    "    \n",
    "#     x = layers.Conv2D(2*filters, 5, strides=stride)(x)\n",
    "#     x = layers.Activation('relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "87Uk3wKiRfQX"
   },
   "outputs": [],
   "source": [
    "def Bottleneck(x, filters, stride=1, conv_shortcut=True, name=None):\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(4 * filters, 1, strides=stride, name=name + '_0_conv')(x)\n",
    "        shortcut = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)\n",
    "    else:\n",
    "        shortcut = x\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=1, strides=1, name=name + '_1_conv')(x)###問1-1-1###\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=3, strides=stride, padding='SAME', name=name + '_2_conv')(x)###問1-1-2###\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(4 * filters, kernel_size=1, strides=1, name=name + '_3_conv')(x)###問1-1-3###\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\n",
    "\n",
    "    x = layers.Add()([shortcut, x])###問1-2###\n",
    "    x = layers.Activation('relu', name=name + '_out')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEZAE-TaD-6l"
   },
   "source": [
    "上記で実装した Bottleneck を用いて、ResNet50 を実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "XPH9m_13QPMA"
   },
   "outputs": [],
   "source": [
    "def myResNet50(classes=1000,model_name='resnet50'):\n",
    "    classifier_activation = 'softmax'\n",
    "    img_input = layers.Input(shape=(224,224,3))\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, name='conv1_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1_relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "\n",
    "    x = Bottleneck(x, 64, name='conv2_block1')\n",
    "    x = Bottleneck(x, 64, conv_shortcut=False, name='conv2_block2')\n",
    "    x = Bottleneck(x, 64, conv_shortcut=False, name='conv2_block3')\n",
    "    x = Bottleneck(x, 128, stride=2, name='conv3_block1')\n",
    "    x = Bottleneck(x, 128, conv_shortcut=False, name='conv3_block2')\n",
    "    x = Bottleneck(x, 128, conv_shortcut=False, name='conv3_block3')\n",
    "    x = Bottleneck(x, 128, conv_shortcut=False, name='conv3_block4')\n",
    "    x = Bottleneck(x, 256, stride=2, name='conv4_block1')\n",
    "    x = Bottleneck(x, 256, conv_shortcut=False, name='conv4_block2')\n",
    "    x = Bottleneck(x, 256, conv_shortcut=False, name='conv4_block3')\n",
    "    x = Bottleneck(x, 256, conv_shortcut=False, name='conv4_block4')\n",
    "    x = Bottleneck(x, 256, conv_shortcut=False, name='conv4_block5')\n",
    "    x = Bottleneck(x, 256, conv_shortcut=False, name='conv4_block6')\n",
    "    x = Bottleneck(x, 512, stride=2, name='conv5_block1')\n",
    "    x = Bottleneck(x, 512, conv_shortcut=False, name='conv5_block2')\n",
    "    x = Bottleneck(x, 512, conv_shortcut=False, name='conv5_block3')\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(classes, activation=classifier_activation,name='predictions')(x)\n",
    "\n",
    "  # Create model\n",
    "    model =  tf.keras.Model(img_input, x, name=model_name)\n",
    "    return model\n",
    "\n",
    "#ResNet50の実装\n",
    "my_ResNet50 = myResNet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vq30xeBQz1y"
   },
   "source": [
    "### 転移学習\n",
    "\n",
    "ResNet では、転移学習 を行います。\n",
    "\n",
    "転移学習とは、事前学習で得られたパラメータを固定し、新たに追加した層のみを学習する手法です。\n",
    "\n",
    "まずは、TensorFlow で配布されている事前学習パラメータを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "9RcprnWh3aIu"
   },
   "outputs": [],
   "source": [
    "BASE_WEIGHTS_PATH = ('https://storage.googleapis.com/tensorflow/keras-applications/resnet/')\n",
    "file_name = 'resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "file_hash = '2cb95161c43110f7111970584f804107'\n",
    "weights_path = data_utils.get_file(file_name,BASE_WEIGHTS_PATH + file_name,cache_subdir='models',file_hash=file_hash)\n",
    "my_ResNet50.load_weights(weights_path)    # 事前学習パラメータの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciIlR7oMKhWm"
   },
   "source": [
    "TensorFlow に実装されている ResNet50 の出力層は 1000クラスを分類するようになっています。  \n",
    "しかし、本演習では飛行機と自動車の 2クラス分類のため出力層を追加する必要があります。\n",
    "\n",
    "<font color=\"Red\">問2. 2クラス分類を行うために出力層を変更してください。出力サイズは`2`とします。</font>\n",
    "\n",
    "【ヒント】\n",
    "\n",
    "`outputs = my_ResNet50.get_layer('avg_pool').output` では「avg_pool」という名前のlayerの出力を取得しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "OgmCD7IdL0ha"
   },
   "outputs": [],
   "source": [
    "sub_model = tf.keras.Model(inputs = my_ResNet50.input, outputs = my_ResNet50.get_layer('avg_pool').output)\n",
    "inputs = sub_model.input\n",
    "x = sub_model(inputs)\n",
    "x = layers.Dense(units=2, activation = 'sigmoid',name='predictions')(x)###問2###\n",
    "new_ResNet50 = tf.keras.Model(inputs,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiA31DCwNdbd"
   },
   "source": [
    "model_resnet50 の160層以上のパラメータのみを学習によって最適化します\n",
    "\n",
    "<font color=\"Red\">問3. 学習率`lr=0.001`, モーメンタム`momentum=0.9`で最適化アルゴリズム`SGD`を完成させてください。</font>\n",
    "\n",
    "【ヒント】`model_resnet50` の160番目までの層の`.trainable`の引数を`False`に与える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "pVePQNeBow6d"
   },
   "outputs": [],
   "source": [
    "for layer in new_ResNet50.layers[-2].layers[0:160]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "76Gyutksj9X9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mssst\\miniconda3\\envs\\avilen-e\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# oprimizer\n",
    "optimizer = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)###問3###\n",
    "# 損失関数\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "#損失の計算\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "#精度の計算\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uahEZVghMNO_"
   },
   "source": [
    "### 学習\n",
    "\n",
    "５エポックで精度が80%以上になっていれば学習成功です。\n",
    "\n",
    "学習には、GPU環境で2~3分ほどかかります。\n",
    "\n",
    "GPU環境でない場合、学習にかなりの時間が必要になると思われます。  \n",
    "Google ColabのGPU環境で実行することを推奨します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "7dBBKtAJlnWq"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3770ec5140e849e6bc2d26d4ba127f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.522720217704773, Accuracy: 72.5999984741211, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc6c64a5632451f91a07ae6f61e842e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.3947025239467621, Accuracy: 82.20000457763672, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea21c2398cd4b82b840476ae9043555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.43258044123649597, Accuracy: 81.5, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c431ecf3c94487b0a716bc6a9b90c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.38440871238708496, Accuracy: 84.0, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5c55eed244441197262817839b2412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.2986506223678589, Accuracy: 86.0999984741211, \n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(x, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = new_ResNet50(x, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss,new_ResNet50.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, new_ResNet50.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "EPOCHS = 5\n",
    "loss_list = []\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    for x, labels in tqdm(train_ds):\n",
    "        train_step(x, labels)\n",
    "    print(f'Epoch {epoch + 1}, 'f'Loss: {train_loss.result()}, 'f'Accuracy: {train_accuracy.result() * 100}, ')\n",
    "    loss_list.append(train_loss.result())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lczrSu0LQoBn"
   },
   "source": [
    "\n",
    "## 2. WideResNetを用いたCIFAR10の分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWrOjomVEcmU"
   },
   "source": [
    "### WideResNetについて\n",
    "\n",
    "WideResNetは、ResNetの層数を減らし各層の次元数を増加させることで精度を向上させるネットワークになっています。\n",
    "\n",
    "このような変更を加えたメリットとして以下が挙げられます。\n",
    "- 次元数を増やすことで、層数が少なくても十分な特徴表現を獲得できる。\n",
    "- 畳み込み層は、次元数が増えたとしても並列計算できるためあまりの計算コストが増加しない。WideResNetではその分層数を減らしているため、より計算コストを削減することができる。\n",
    "\n",
    "また、層を深くしたWideResNetでは畳み込み層の間にDropoutを用いることで、精度が向上することも報告されている。\n",
    "\n",
    "### bottleneckのアーキテクチャ\n",
    "\n",
    "WideResNetのbottleneckとResnetのbottleneckの違いは、畳み込み層の2層目の次元数をk倍している部分です。\n",
    "\n",
    "以下の図の例では、`k=2`を採用しています。\n",
    "\n",
    "<img src=\"data:image/jpeg;base64,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\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4asOZcjlK_k"
   },
   "source": [
    "### WideResNet の実装\n",
    "\n",
    "ResNet に引き続き、WideResNet も Residual Block のみを自ら実装してみましょう。  \n",
    "ResNet 同様、Residual Block は Bottleneck アーキテクチャになります。\n",
    "\n",
    "* <font color=\"Red\">問4. WideResNet の Bottleneckレイヤー を完成させてください。</font>\n",
    "  * <font color=\"Red\">問4-1. ダウンサンプリングを行う処理を記述してください。<br>\n",
    "    なお、コード入力の際は下記コードの```[a]```および```[b]```の部分に適切な変数または数値を入力してから転記してください。</font><br>\n",
    "      * 問4-1-1 ```layers.Conv2D([a-1], [b-1], strides=stride, name=name + '_1_conv')(x)```<br>\n",
    "      * 問4-1-2 ```layers.Conv2D([a-2], [b-2], padding='SAME', name=name + '_2_conv')(x)```<br>\n",
    "      * 問4-1-3 ```layers.Conv2D([a-3], [b-3],name=name + '_3_conv')(x)```<br>\n",
    "  * <font color=\"Red\">問4-2. skip connectionを行う処理を記述してください。</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "BMrO3RAcEcmV"
   },
   "outputs": [],
   "source": [
    "def WideBottleneck(x, filters, stride=1, conv_shortcut=True, name=None):\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(4 * filters, 1, strides=stride,name=name + '_0_conv')(x)\n",
    "        shortcut = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,name=name + '_0_bn')(shortcut)\n",
    "    else:\n",
    "        shortcut = x\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=1, strides=stride, name=name + '_1_conv')(x)###問4-1-1###\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(2 * filters, kernel_size=3, padding='SAME', name=name + '_2_conv')(x)###問4-1-2###\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(4 * filters, kernel_size=1,name=name + '_3_conv')(x)###問4-1-3###\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\n",
    "\n",
    "    x = layers.Add()([shortcut, x])###問4-2###\n",
    "    x = layers.Activation('relu', name=name + '_out')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3cUWosbEcmV"
   },
   "source": [
    "上記で実装した WideBottleneck を用いて、WideResNet50 を実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "EJ4urb6lEcmV"
   },
   "outputs": [],
   "source": [
    "def myWideResNet50(classes=1000,model_name='resnet50'):\n",
    "    classifier_activation = 'softmax'\n",
    "    img_input = layers.Input(shape=(224,224,3))\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, name='conv1_conv')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1_relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "\n",
    "    x = WideBottleneck(x, 64, name='conv2_block1')\n",
    "    x = WideBottleneck(x, 64, conv_shortcut=False, name='conv2_block2')\n",
    "    x = WideBottleneck(x, 64, conv_shortcut=False, name='conv2_block3')\n",
    "    x = WideBottleneck(x, 128, stride=2, name='conv3_block1')\n",
    "    x = WideBottleneck(x, 128, conv_shortcut=False, name='conv3_block2')\n",
    "    x = WideBottleneck(x, 128, conv_shortcut=False, name='conv3_block3')\n",
    "    x = WideBottleneck(x, 128, conv_shortcut=False, name='conv3_block4')\n",
    "    x = WideBottleneck(x, 256, stride=2, name='conv4_block1')\n",
    "    x = WideBottleneck(x, 256, conv_shortcut=False, name='conv4_block2')\n",
    "    x = WideBottleneck(x, 256, conv_shortcut=False, name='conv4_block3')\n",
    "    x = WideBottleneck(x, 256, conv_shortcut=False, name='conv4_block4')\n",
    "    x = WideBottleneck(x, 256, conv_shortcut=False, name='conv4_block5')\n",
    "    x = WideBottleneck(x, 256, conv_shortcut=False, name='conv4_block6')\n",
    "    x = WideBottleneck(x, 512, stride=2, name='conv5_block1')\n",
    "    x = WideBottleneck(x, 512, conv_shortcut=False, name='conv5_block2')\n",
    "    x = WideBottleneck(x, 512, conv_shortcut=False, name='conv5_block3')\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(classes, activation=classifier_activation,name='predictions')(x)\n",
    "\n",
    "  # Create model\n",
    "    model =  tf.keras.Model(img_input, x, name=model_name)\n",
    "    return model\n",
    "\n",
    "#WideResNet50の実装\n",
    "my_WideResNet50 = myWideResNet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lN7U0aQmSM_b"
   },
   "source": [
    "さらに、2クラス分類に2クラス分類のため出力層を追加しましょう。\n",
    "\n",
    "<font color=\"Red\">問5. 2クラス分類を行うために出力層を追加してください。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "-U0AqK4tc8du"
   },
   "outputs": [],
   "source": [
    "sub_wide_model = tf.keras.Model(inputs = my_WideResNet50.input, outputs =my_WideResNet50.get_layer('avg_pool').output)\n",
    "inputs = sub_wide_model.input\n",
    "x = sub_wide_model(inputs)\n",
    "x = layers.Dense(units=2, activation = 'sigmoid',name='predictions')(x)###問5###\n",
    "new_WideResNet50 = tf.keras.Model(inputs,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTxg9cmkQw2p"
   },
   "source": [
    "<font color=\"Red\">問6. 学習率`lr=0.001`, モーメンタム`momentum=0.9`で最適化アルゴリズム`SGD`を完成させてください。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "QrbLt7opTcmw"
   },
   "outputs": [],
   "source": [
    "# oprimizer\n",
    "optimizer = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)###問6###\n",
    "# 損失関数\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "#損失の計算\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "#精度の計算\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U69AutJDUU_F"
   },
   "source": [
    "### 学習\n",
    "\n",
    "５エポックで精度が80%以上になっていれば学習成功です。学習には、GPU環境で6～8分ほどかかります。\n",
    "\n",
    "GPU環境でない場合は、学習に60～90分ほど必要になります。Google ColabのGPU環境で実行することを推奨します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "7T5NN9UoTcmz"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3654830aca144b1187f9ce4bf6b269b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0645830631256104, Accuracy: 65.9000015258789, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a84b88bd7ad41f8b52e48489d551838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.7358579635620117, Accuracy: 72.29999542236328, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81758f69da84b479412f4656fe85f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.7736756801605225, Accuracy: 76.30000305175781, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cc868f9fdc4376b18e0f6ffce47d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.6524447202682495, Accuracy: 78.19999694824219, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c331f517ec4b5d879a345799a8cf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.6020799875259399, Accuracy: 81.19999694824219, \n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(x, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = new_WideResNet50(x, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, new_WideResNet50.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, new_WideResNet50.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "EPOCHS = 5\n",
    "loss_list = []\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    for x, labels in tqdm(train_ds):\n",
    "        train_step(x, labels)\n",
    "    print(f'Epoch {epoch + 1}, 'f'Loss: {train_loss.result()}, 'f'Accuracy: {train_accuracy.result() * 100}, ')\n",
    "    loss_list.append(train_loss.result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BM0FWoSoWgh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "コーディング演習Chapter10.ipynb",
   "provenance": [
    {
     "file_id": "1KbHMU2rGfYgtsNQYO3BAJrYw7TSEjNIg",
     "timestamp": 1648102930351
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
